{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103e971-5315-45aa-8ff7-88936e811590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f1648-ec8b-43b9-a546-8ba3fbd5a3dd",
   "metadata": {},
   "source": [
    "# Links used for the following code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f30e3-6ddc-4528-9b04-8cf3e4fd66a6",
   "metadata": {},
   "source": [
    "#### 1) https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/\n",
    "2) https://pyimagesearch.com/2021/04/05/opencv-face-detection-with-haar-cascades/\n",
    "3) https://medium.com/analytics-vidhya/haar-cascades-explained-38210e57970d\n",
    "4) https://pyimagesearch.com/2018/09/24/opencv-face-recognition/ -- face net\n",
    "5) https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/ - adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0522e-02bf-4120-8415-373c6cce0b36",
   "metadata": {},
   "source": [
    "The below module does the following "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d3c47-e994-4210-94b7-2875eccc0646",
   "metadata": {},
   "source": [
    "1. Detect faces using haar cascade\n",
    "2. Crop faces\n",
    "3. Visualize them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cb58a-0ae1-420f-ade1-2d9f138c4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.CascadeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912f5c9-d644-49dc-96a9-14d72d7dfe78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b902509-e3e4-418b-9f9e-7e4ceb48583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this as a user input \n",
    "\n",
    "path_to_raw_data = \"C:\\\\Users\\\\mirza\\\\ASU\\\\my_projects\\\\face_recog\\\\Face_recog\\\\data\\\\\"\n",
    "dataset_path = \"C:\\\\Users\\\\mirza\\\\ASU\\\\my_projects\\\\face_recog\\\\Face_recog\\\\dataset\\\\\"\n",
    "# make .py file with the function below and add arguments to it\n",
    "    # i) The input should be multiple paths to images\n",
    "\n",
    "#labels = [\"Aarav\", \"Raghav\", \"Others\"]\n",
    "    \n",
    "\n",
    "def get_crop_faces(path_to_raw_data, dataset_path):\n",
    "    print(\"[INFO] loading face detector...\")\n",
    "    haar_cascade = cv2.CascadeClassifier(r\"C:\\Users\\mirza\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml\")\n",
    "    labels = os.listdir(path_to_raw_data)\n",
    "    for each in labels:\n",
    "        os.makedirs(dataset_path + each, exist_ok = True)\n",
    "    # create the parent folder as dataset and save the correspoding labels\n",
    "    i = 0\n",
    "    for each_label in labels:\n",
    "        list_images = os.listdir(os.path.join(path_to_raw_data, each_label))\n",
    "        for each_image in list_images:      \n",
    "            path_to_image = os.path.join(path_to_raw_data,each_label,each_image)        \n",
    "            print(path_to_image)\n",
    "            each_image_org = cv2.imread(os.path.join(path_to_image))\n",
    "            # using imutils to keep the aspect ratio\n",
    "            each_image_gray = cv2.cvtColor(each_image_org, cv2.COLOR_BGR2GRAY)\n",
    "            each_image_gray = imutils.resize(each_image_gray, width=700)\n",
    "            print(each_image_gray.shape)\n",
    "            # Applying the face detection method on the grayscale image\n",
    "            faces_rect = haar_cascade.detectMultiScale(each_image_gray)# 1.1, 9)\n",
    "            print(faces_rect)\n",
    "            # Iterating through rectangles of detected faces\n",
    "            detect_face_flag = True\n",
    "            if len(faces_rect) == 0:\n",
    "                print(\"Couldnt detect any face\")\n",
    "                detect_face_flag = False                \n",
    "            if not detect_face_flag:\n",
    "                # save the undetected images and manually do it, or find some other way\n",
    "                continue\n",
    "            #for (x, y, w, h) in faces_rect:            \n",
    "                #print(x, y, w, h)\n",
    "                #disp_image = cv2.rectangle(each_image_gray.copy(), (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            #cv2.imshow('Detected faces', disp_image)\n",
    "            # crop using the coordinates\n",
    "            face_1 = each_image_gray[faces_rect[0][1]:faces_rect[0][1] + faces_rect[0][3], faces_rect[0][0]: faces_rect[0][0] + faces_rect[0][2]]\n",
    "            #each_image_org[faces_rect[0][1]:faces_rect[0][1] + faces_rect[0][3], faces_rect[0][0]: faces_rect[0][0] + faces_rect[0][2]]\n",
    "            cv2.imwrite(os.path.join(dataset_path, each_label, each_image), face_1)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f259e4-1c69-4180-98ac-122063960fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment the code with different methods:\n",
    "    # instead of gray scaling the images\n",
    "    # change the resize variable\n",
    "    # changing the function parameters for haar cascade, minsize etc - low priority\n",
    "\n",
    "    \n",
    "# theory \n",
    "    # 1) Understand images as a matrix\n",
    "        # \n",
    "    # 2) Understand matrix can also be viewed as functions and transformations, \n",
    "    # 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac524f-d445-4273-9e88-9f2d8601b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions \n",
    "# Get to know how the features( extracted from the kernels) are used for faces and eyes.\n",
    "\n",
    "    # Mirza to do \n",
    "    # i)https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf -- get the concept in detail\n",
    "    # adaboost paper - \n",
    "        # i) Decision Trees\n",
    "        # ii) Random forest \n",
    "        # iii) Boosting algorithm\n",
    "        \n",
    "        # how the error ( lowest error propagated to next iteration)\n",
    "    # thresholding \n",
    "        # i) https://developers.google.com/machine-learning/crash-course/classification/thresholding\n",
    "        # ii) Probability \n",
    "    # cascading classifier - \n",
    "    \n",
    "    # write an overview \n",
    "    \n",
    "    # \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81557294-c1cb-42f0-8ce0-d5b3cd1c6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_crop_faces(path_to_raw_data, dataset_path)        \n",
    "# remove any false positives - this has to be manually "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ef7ce-eee3-47a1-9aad-18993c95b77c",
   "metadata": {},
   "source": [
    "Build an image classifier \n",
    "\n",
    "https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf\n",
    "\n",
    "Step #1: Extract embeddings from face dataset\n",
    "    i) Literature review for embedding and facenet svm\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad0349-0376-4277-bed2-e6e00f894b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After next code push\n",
    "    # https://www.cv-foundation.org/openaccess/content_cvpr_2015/app/1A_089.pdf\n",
    "    \n",
    "    # Suppport vector machines \n",
    "    \n",
    "    # \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
